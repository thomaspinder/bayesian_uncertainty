---
title: "Result Plots"
author: "Thomas Pinder"
date: "18 August 2018"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_sections: true
    theme: united

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('.')
library(dplyr, warn.conflicts = FALSE)
library(ggplot2, warn.conflicts = FALSE)
library(reshape2)
library(knitr)
library(purrr)
library(readr)
library(ggmcmc)
library(scales)
require(gridExtra)
source('BEST.R')
```

# Initial Work
### Read in Data
```{r}
cnn_results <- read.csv('cnn_exp3_all.csv')
bcnn_results<- read.csv('bcnn_exp3_all.csv')
cnn_results$method <- 'cnn'
bcnn_results$method <- 'bcnn'
bcnn_rbind <- bcnn_results %>% 
  select(c('X', 'original', 'adversary', 'truth', 'epsilon', 'method'))

results <- rbind(cnn_results, bcnn_rbind)
```

### Set GGPlot Theme Config

```{r}
theme_new <- theme_set(theme_bw())

theme_new <- theme_update(axis.text=element_text(size=42), axis.title=element_text(size=14,face="bold"))
```

## Calculate Overall Accuracies

# MNIST Analysis
## High Level non-Bayesian analysis
### Overall Accuracies
```{r}
results %>% 
  mutate(orig_result = ifelse(original==truth, 1, 0), 
         adv_result = ifelse(adversary==truth, 1, 0)) %>% 
  group_by(method) %>% 
  summarise(orig_acc = 100*sum(orig_result)/n(),
            adv_acc = 100*sum(adv_result/n()))
```


### Exploratory HeatMap

```{r}
res_hmap <-results %>% 
  select(c(original, truth, method)) %>% 
  group_by(truth, method) %>% 
  mutate(truth_count=n()) %>% 
  ungroup() %>% 
  group_by(original, truth, method, truth_count) %>% 
  summarise(depth = n()) %>% 
  mutate(fill = depth/truth_count) %>% 
  ggplot(aes(x=as.factor(original), y = as.factor(truth), fill=fill)) +
  geom_tile(colour='white') +
  scale_fill_gradient(low='mintcream', high = 'steelblue', labels=percent(0.2*0:5),
       breaks=0.2*0:5 ) +
  labs(x='Prediction', y='Truth', fill='Accuracy (%)')+
  geom_text(aes(label = percent(fill)), size=6) +
  facet_grid(~method) +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28), strip.text.x = element_text(size=28)) +
  guides(fill=guide_legend(
                 keywidth=0.1,
                 keyheight=0.1,
                 default.unit="inch")
      )

res_hmap
ggsave('plots/res_hmap.pdf', plot = res_hmap, width = 45, height=26, units = 'cm', dpi = 300)

```
__Fix Colouring lower scale and make gradients labels better spaced and percentages. Try overlaying numbers onto tiles.__


### Calculate Proportion Correct

```{r}
results_eps <- results %>% 
  mutate(original_correct = ifelse(original == truth, 1, 0), 
         adversary_correct = ifelse(adversary == truth, 1, 0)) %>% 
  group_by(method, epsilon) %>% 
  summarise(original_perc = sum(original_correct)/n(),
            adversary_perc = sum(adversary_correct)/n(),
            adv_err = 1.96*(var(adversary_correct)/sqrt(n()))) %>% 
  melt(id.vars=c('epsilon', 'method', 'adv_err'))
```



### Epsilon and accuracy correlation
```{r}
ep_vs_acc <- lm(I(value-0.984) ~ 0 +epsilon , data=results_eps )
summary(ep_vs_acc)
```

### Plot MNIST Acc. vs Epsilon

```{r}
pd <- position_dodge(0.1) # move them .05 to the left and right
p <- results_eps %>%
  filter(variable=='adversary_perc') %>% 
  filter(epsilon<1.01) %>% 
  ggplot(aes(x=epsilon, y=value, colour=method)) +
  geom_line(size=2, alpha =0.6)+
  geom_point(size = 3) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels = seq(0, 1, 0.1), breaks = seq(0,1, 0.1))+
  geom_errorbar(aes(ymin=value-adv_err, ymax=value+adv_err), width=0.08) +
  scale_colour_discrete('Evaluation', labels=c('BCNN', 'CNN')) +
  geom_hline(yintercept=0.1, size=2, alpha =0.8) +
  labs(x = expression(epsilon), y= 'Accuracy (%)', colour='Evaluation', title=expression(paste('Effects of ', epsilon, ' on A Network\'s Accuracy', sep =''))) +
  annotate("text", x= 0.6, y =0.15,label = 'Random Guessing', size=7)+
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

p 
ggsave('plots/fgsm_acc.pdf', plot = p, width = 40, height=22, units = 'cm', dpi = 300)
```

### Assessing Uncertainty
```{r}

bcnn_results <- bcnn_results %>% 
  mutate(result = ifelse(adversary == truth, 1, 0),
         uncertainty_delta = adversary_confidence - original_confidence)

bcnn_confs <- bcnn_results %>% 
  group_by(result, epsilon) %>% 
  summarise(avg_adv_conf = mean(adversary_confidence),
            n = n(), 
            conf_adv_se = 1.96*(sqrt(var(adversary_confidence)/n())),
            orig_conf = mean(original_confidence),
            orig_se = 1.96*(sqrt(var(original_confidence)/n())))


ttest_adv <- t.test(bcnn_results$adversary_confidence, bcnn_results$original_confidence)
```



## Bayesian Inference MNIST
We can compute the Bayesian equivalent of this p-value through the following

### Visualise data distributions
```{r}
set.seed(123)
bcnn_results_f <- bcnn_results %>% 
  filter(epsilon < 0.8) %>% 
  filter(epsilon > 0.4)
adv_conf <- sample(bcnn_results_f$adversary_confidence, size = 1000, replace = FALSE)
original_conf <- sample(bcnn_results_f$original_confidence, size=1000, replace = FALSE)
pooled <- c(adv_conf, original_conf)
# 
# # Visaulise
# bcnn_hist <-bcnn_results %>% 
#   select(c(method, adversary_confidence, original_confidence)) %>% 
#   melt(id.vars='method') %>% 
#   ggplot(aes(x=value, fill=variable)) + 
#   geom_histogram(bins=50) +
#   scale_fill_discrete('Image Type', labels=c('Adversarial Example', 'Original')) +
#   facet_wrap(~variable) +
#   theme_bw() +
#   theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
#         legend.text=element_text(size=28), legend.title = element_text(size=28))
# 
# bcnn_hist
# # Save
# ggsave('plots/bcnn_uncertainties_hist.pdf', plot = bcnn_hist, width = 50, height=22, units = 'cm', dpi = 300)
```




### Specify priors and likelihoods

```{r}
likelihood <- function(parameters){
  mu1=parameters[1]; sig1=parameters[2]; mu2=parameters[3]; sig2=parameters[4]
  prod(dnorm(adv_conf, mu1, sig1)) * prod(dnorm(original_conf, mu2, sig2))
}

prior <- function(parameters){
  mu1=parameters[1]; sig1=parameters[2]; mu2=parameters[3]; sig2=parameters[4]
  dnorm(mu1, mean(pooled), 1000*sd(pooled)) * dnorm(mu2, mean(pooled), 1000*sd(pooled)) * dexp(sig1, rate=0.1) * dexp(sig2, 0.1)
}
```


### And the Posterior

```{r}
posterior <- function(parameters) {likelihood(parameters) * prior(parameters)}
```




### Use MH to get our Posterior
#### Define Our Model
```{r}
cat("model {
    for (i in 1:Ntotal) {
        y[i] ~ dt(mu[x[i]], tau[x[i]], nu)
    }
    for (j in 1:2) {
        mu[j] ~ dnorm(mu_pooled, tau_pooled)
        tau[j] <- 1 / pow(sigma[j], 2)
        sigma[j] ~ dunif(sigma_low, sigma_high)
    }
    nu <- nu_minus_one + 1
    nu_minus_one ~ dexp(1 / 29)
}", file = 'mhastings.txt')

```

```{r}
library(rjags)
library(coda)
mu1 = 0.01; sig1 = 10; mu2 = 0.01; sig2 = 10
parameters <- c(mu1, sig1, mu2, sig2)


# Indicator variable
x <- c(rep(1, length(adv_conf)), rep(2, length(original_conf)))

# Initialise model
cpd.model <- jags.model(file='mhastings.txt',
                        data=list(y=pooled,
                                  x=x,
                                  mu_pooled=mean(pooled),
                                  tau_pooled=1/(1000 * sd(pooled))^2,
                                  sigma_low=sd(pooled) / 1000,
                                  sigma_high=sd(pooled) * 1000,
                                  Ntotal=length(pooled)))
# Run
update(cpd.model, 1000)
chain <- coda.samples(model = cpd.model, n.iter = 10000,
                      variable.names = c('mu', 'sigma'))
plot(chain)
rchain <- as.matrix(chain)

P <- data.frame(
  Parameter=c("mu[1]", "mu[2]", "sigma[1]", "sigma[2]"),
  Label=c("Adversarial Mu", "Original Mu", "Adversarial Sigma", 'Original Sigma'))
s <- ggs(chain, par_labels=P)

trace_ps <- ggs_traceplot(s) +theme_bw()
density_ps <- ggs_density(s)+theme_bw()
to_save <- arrangeGrob(trace_ps, density_ps, ncol=2, nrow=1)
ggsave('plots/advs_mh.pdf', plot = to_save, width = 40, height=22, units = 'cm', dpi = 300)

rchain_df <- data.frame(rchain)
colnames(rchain_df) <- c('Adversarial Mu', 'Original Mu', 'sig1', 'sig2')
post_mus <- rchain_df %>% 
  select(c('Adversarial Mu', 'Original Mu')) %>% 
  melt() %>% 
  ggplot(aes(x = value, fill=variable)) +
  geom_density(alpha=0.7) +
  labs(x='Posterior Mean Values', title='Densities of Posterior Values for Mu',y = 'Desnity', fill='Adversarial Presence') +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

ggsave('plots/posterior_mus.pdf', plot = post_mus, width = 50, height=30, units = 'cm', dpi = 300)

par(mfrow=c(1,1))
hist(rchain[, 'mu[1]'] - rchain[, 'mu[2]'])
mean(rchain[, 'mu[1]'] - rchain[, 'mu[2]'] > 0)
```


### Visualise Posterior
```{r}
post_means <- colMeans(rchain_df)
adv_post_samps <- rnorm(100000, mean = post_means[1], sd=post_means[3])
ori_post_samps <- rnorm(100000, mean = post_means[2], sd=post_means[4])

posteriors <- data.frame(Present=adv_post_samps, Absent=ori_post_samps)
post_dists <- posteriors %>% 
  melt() %>% 
  ggplot(aes(x=value, fill=variable)) +
  geom_density(alpha=0.7) +
  labs(x='Uncertainty Value', title='Posterior Densities For Uncertainty Estimates',y = 'Density', fill='Adversarial Presence') +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

ggsave('plots/post_dists.pdf', plot = post_dists, width = 50, height=30, units = 'cm', dpi = 300)

```

### Test Probability That Adversarial Uncertainty is Less than Unperturbed Uncertainty
```{r}
sum(posteriors$Present-posteriors$Absent>0)
posteriors$diff <- posteriors$Present-posteriors$Absent
posteriors$group <- 'a'

#plot cdf
diff_cdf <- posteriors %>% 
  ggplot(aes(x = diff, fill=group)) +
  stat_ecdf(size=3) +
  labs(x=expression(paste('Uncertainty Difference, ', Delta)), y=expression(paste('F(', Delta, ')')), title='CDF of Differences for 100000 Posterior Samples') +
  scale_fill_discrete(guide=FALSE) +
  scale_x_continuous(limits=c(-0.001, 0.007),
                     breaks = seq(-0.001, 0.007, by =0.002))+
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))



ggsave('plots/diff_cdf.pdf', plot = diff_cdf, width = 50, height=30, units = 'cm', dpi = 300)
```


### Testing The BEST Library
```{r}
best_samples <- bcnn_results %>% 
  filter(epsilon < 0.6 & epsilon > 0.3)

adv <- sample(best_samples$adversary_confidence, 1000, FALSE)
ori <- sample(best_samples$original_confidence, 1000, FALSE)

mcmcChain <- BESTmcmc(adv, ori)
mcmc_results <- BESTplot(adv, ori, mcmcChain)
```


# X-Ray Analysis

### Load in Data
```{r}
xray <- read.csv('xray_mc.csv')
kable(head(xray))
xray <- xray %>% 
  mutate(standard_correct = ifelse(standard_pred==truth, 1,0),
         mc_correct = ifelse(mc_pred==truth, 1, 0))
mc_acc = round((sum(xray$mc_correct)/dim(xray)[1])*100, 2)
st_acc = round((sum(xray$standard_correct)/dim(xray)[1])*100, 2)
```


### Test Recall and Precision 
#### Mone Carlo CNN
```{r}
library(e1071)
library(caret)

mc_c_matrix <- confusionMatrix(as.factor(xray$mc_pred), reference = as.factor(xray$truth))
kable(mc_c_matrix$table)
mc_cm_df <- data.frame(mc_c_matrix$table)
mc_cm <- mc_cm_df %>% 
  ggplot(aes(x=Reference, y=Prediction, fill=Freq)) + 
  geom_tile() +
  geom_text(aes(label=Freq), colour='white', size=14) +
  labs(x='Ground Truth', y='Prediction', title='BCNN Confusion Matrix') +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

```
#### Standard CNN
```{r}
library(e1071)
library(caret)
s_c_matrix <- confusionMatrix(as.factor(xray$standard_pred), reference = as.factor(xray$truth))
kable(s_c_matrix$table)
cn_cm_df <- data.frame(s_c_matrix$table)
cn_cm <- cn_cm_df %>% 
  ggplot(aes(x=Reference, y=Prediction, fill=Freq)) + 
  geom_tile() +
  geom_text(aes(label=Freq), colour='white', size=14) +
  labs(x='Ground Truth', y='Prediction', title='CNN Confusion Matrix') +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

con_mats <- arrangeGrob(cn_cm, mc_cm, ncol=2)
ggsave('plots/xray_cms.pdf', plot = con_mats, width = 50, height=30, units = 'cm', dpi = 300)
```

```{r}
mc_rec <- recall(mc_c_matrix$table)
mc_prec <- precision(mc_c_matrix$table)
cnn_rec <- recall(s_c_matrix$table)
cnn_prec <- precision(s_c_matrix$table)
print(paste('BCNN Recall: ', mc_rec, sep=''))
print(paste('BCNN Precision: ', mc_prec, sep=''))
print(paste('CNN Recall: ', cnn_rec, sep=''))
print(paste('CNN Precision: ', cnn_prec, sep=''))
```

## X-Ray Adversaries
### Load Data
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Merge files
all_files <- list.files('xray_adv', pattern = '*.csv', full.names = TRUE)
xray_advs <- map_df(all_files, read_csv, .id='id')
# kable(head(xray_advs))
```



### Calculate Performance
```{r}
xray_advs <- xray_advs %>% 
  mutate(orig_correct = ifelse(standard_pred==truth, 1, 0),
         mc_correct = ifelse(mc_pred==truth, 1, 0), 
         orig_adv_correct = ifelse(cnn_adv==truth, 1, 0),
         mc_adv_correct = ifelse(mc_adv==truth, 1, 0),
         mc_fooled = ifelse(mc_correct==1 && mc_adv_correct==1, 1, 0))

xray_eps_g <- xray_advs %>% 
  select(c(orig_adv_correct, mc_adv_correct, epsilon)) %>%
  filter(epsilon < 1) %>% 
  melt(id.vars='epsilon') %>% 
  group_by(epsilon, variable) %>% 
  summarise(acc = sum(value)/n()) %>% 
  ggplot(aes(x = epsilon, y=acc, colour=variable)) +
  geom_hline(yintercept=0.5, size=2, alpha =0.8) +
  annotate("text", x= 0.6, y =0.15,label = 'Random Guessing', size=7)+
  geom_line()+
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(breaks = seq(0,1, 0.1)) +
  scale_colour_discrete('Evaluation', labels=c('CNN', 'BCNN')) +
  labs(x = expression(epsilon), y= 'Accuracy (%)', colour='Evaluation', title=expression(paste('Effects of ', epsilon, ' on A Network\'s Accuracy Predicting Pneumonia', sep =''))) +
  geom_point() +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=32),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

ggsave('plots/xray_eps.pdf', plot = xray_eps_g, width = 50, height=30, units = 'cm', dpi = 300)

```



### Recall and Precision
```{r}
library(caret)

confusionMatrix(as.factor(xray_advs$mc_adv), as.factor(xray_advs$truth))
```
### Average Confidence

```{r}
xray_advs %>% 
  group_by(mc_correct) %>% 
  summarise(avg_conf = mean(mc_conf_1))

xray_advs %>% 
  select(c(mc_correct, mc_conf)) %>% 
  ggplot(aes(x=mc_conf, colour=as.factor(mc_correct))) +
           geom_density(bw=0.06)
```

### Assess Xray uncertainties
```{r}
xray_uncs <- xray_advs %>% 
  filter(epsilon > 0.01) %>% 
  filter(epsilon < 0.5)

xr_ori <- xray_uncs$mc_conf
xr_adv <- xray_uncs$mc_conf_1
xr_pooled <- c(xr_adv, xr_ori)

# Standard t-test
t.test(xr_adv, xr_ori, alternative = 'greater')

# MCMC
mu1 = 0.01; sig1 = 10; mu2 = 0.01; sig2 = 10
parameters <- c(mu1, sig1, mu2, sig2)


# Indicator variable
x <- c(rep(1, length(xr_adv)), rep(2, length(xr_ori)))

# Initialise model
xr.cpd.model <- jags.model(file='mhastings.txt',
                        data=list(y=xr_pooled,
                                  x=x,
                                  mu_pooled=mean(xr_pooled),
                                  tau_pooled=1/(1000 * sd(xr_pooled))^2,
                                  sigma_low=sd(xr_pooled) / 1000,
                                  sigma_high=sd(xr_pooled) * 1000,
                                  Ntotal=length(xr_pooled)))
# Run
update(xr.cpd.model, 1000)
xr_chain <- coda.samples(model = cpd.model, n.iter = 10000,
                      variable.names = c('mu', 'sigma'))
plot(xr_chain)
xr_rchain <- as.matrix(xr_chain)

P <- data.frame(
  Parameter=c("mu[1]", "mu[2]", "sigma[1]", "sigma[2]"),
  Label=c("Adversarial Mu", "Original Mu", "Adversarial Sigma", 'Original Sigma'))
xr_s <- ggs(xr_chain, par_labels=P)

xr_trace_ps <- ggs_traceplot(xr_s) +theme_bw()
xr_density_ps <- ggs_density(xr_s)+theme_bw()
xr_to_save <- arrangeGrob(xr_trace_ps, xr_density_ps, ncol=2, nrow=1)
ggsave('plots/xr_advs_mh.pdf', plot = xr_to_save, width = 40, height=22, units = 'cm', dpi = 300)

xr_rchain_df <- data.frame(xr_rchain)
colnames(xr_rchain_df) <- c('Adversarial Mu', 'Original Mu', 'sig1', 'sig2')
xr_post_mus <- xr_rchain_df %>% 
  select(c('Adversarial Mu', 'Original Mu')) %>% 
  melt() %>% 
  ggplot(aes(x = value, fill=variable)) +
  geom_density(alpha=0.7) +
  labs(x='Posterior Mean Values', title='Densities of Posterior Values for Mu',y = 'Desnity', fill='Adversarial Presence') +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

ggsave('plots/xr_post_mus.pdf', plot = xr_post_mus, width = 50, height=30, units = 'cm', dpi = 300)

```


### Visualise XRay Posterior
```{r}
xr_post_means <- colMeans(xr_rchain_df)
xr_adv_post_samps <- rnorm(100000, mean = xr_post_means[1], sd=xr_post_means[3])
xr_ori_post_samps <- rnorm(100000, mean = xr_post_means[2], sd=xr_post_means[4])

xr_posteriors <- data.frame(Present=xr_adv_post_samps, Absent=xr_ori_post_samps)
xr_post_dists <- xr_posteriors %>% 
  melt() %>% 
  ggplot(aes(x=value, fill=variable)) +
  geom_density(alpha=0.7) +
  labs(x='Uncertainty Value', title='Posterior Densities For Uncertainty Estimates in X-Ray Images',y = 'Density', fill='Adversarial Presence') +
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

ggsave('plots/xr_post_dists.pdf', plot = xr_post_dists, width = 50, height=30, units = 'cm', dpi = 300)
```


### Test for Posterior Differences 
```{r}
sum(xr_posteriors$Present-xr_posteriors$Absent>0)
xr_posteriors$diff <- xr_posteriors$Present-xr_posteriors$Absent
mean(xr_posteriors$Present-xr_posteriors$Absent >0)

#plot cdf
xr_diff_cdf <- xr_posteriors %>% 
  ggplot(aes(x = diff)) +
  stat_ecdf(size=3) +
  labs(x=expression(paste('Uncertainty Difference, ', Delta)), y=expression(paste('F(', Delta, ')')), title='CDF of Differences for 100000 Posterior Samples In Pneumonia X-Rays') +
  scale_fill_discrete(guide=FALSE) +
  # scale_x_continuous(limits=c(-0.005, 0.01),
  #                    breaks = seq(-0.005, 0.01, by =0.001))+
  theme_bw() +
  theme(axis.text=element_text(size=30), axis.title = element_text(size=28), plot.title=element_text(size=36),
        legend.text=element_text(size=28), legend.title = element_text(size=28))

# xr_diff_cdf

ggsave('plots/xr_diff_cdf.pdf', plot = xr_diff_cdf, width = 50, height=30, units = 'cm', dpi = 300)
```

